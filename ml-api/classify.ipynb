{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from yellowbrick.regressor.residuals import ResidualsPlot, PredictionError\n",
    "from yellowbrick.regressor.alphas import AlphaSelection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253815"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('processed_posts.csv')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleanup, Outlier Removal, Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates('title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gt20'] = data['ups'] > 20\n",
    "data['gt50'] = data['ups'] > 50\n",
    "data['gt100'] = data['ups'] > 100\n",
    "data_sub = data[['title', 'gt20', 'gt50', 'gt100']]\n",
    "data_sub.is_copy = False\n",
    "# data_sub['gt20'] = pd.factorize(data_sub['gt20'])[0]\n",
    "\n",
    "\n",
    "train_titles, test_titles, train_labels, test_labels = train_test_split(data_sub.title, \n",
    "                                                                        data_sub.gt20, \n",
    "                                                                        test_size=0.20,\n",
    "                                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Titles: \t253815\n",
      "Max Length of Title: \t300 characters\n",
      "Avg Length of Title: \t61 characters\n",
      "Max words in Title: \t67 words\n",
      "Avg words in Title: \t10 words\n"
     ]
    }
   ],
   "source": [
    "# Stats for Upvotes\n",
    "num_of_titles = len(data_sub['title'])\n",
    "max_len_title = max([len(x) for x in data_sub['title']])\n",
    "avg_len_title = int(np.mean([len(x) for x in data_sub['title']]))\n",
    "max_word_count = max([len(x.split()) for x in data_sub['title']])\n",
    "avg_word_count = int(np.mean([len(x.split()) for x in data_sub['title']]))\n",
    "\n",
    "print('Number of Titles: \\t{0}'.format(num_of_titles))\n",
    "print('Max Length of Title: \\t{0} characters'.format(max_len_title))\n",
    "print('Avg Length of Title: \\t{0} characters'.format(avg_len_title))\n",
    "print('Max words in Title: \\t{0} words'.format(max_word_count))\n",
    "print('Avg words in Title: \\t{0} words'.format(avg_word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "              ('tfidf', TfidfVectorizer(ngram_range=(1,3), stop_words='english')),\n",
    "              ('clf', MultinomialNB())\n",
    "             ]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe.fit(train_titles, train_labels)\n",
    "pipe.predict([\"Donald Trump attacks UN human rights council for including human rights abusers\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  My Aunt's Husband posted on her Facebook these words of wisdom about Christmas...\n",
      "Greater than 20 Votes:  False\n",
      "Prediction:  False\n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "print('Title: ', test_titles.iloc[index])\n",
    "print('Greater than 20 Votes: ', test_labels.iloc[index])\n",
    "print('Prediction: ', pipe.predict([test_titles.iloc[index]])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64688848176821701"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X=test_titles, y=test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
